Create a script file (for example /run/export_to_blob.sh):
sudo vim /home/jenkinsadmin/export_to_blob.sh

#!/bin/bash
# ================================
# SQL → CSV → Azure Blob Automation
# ================================

set -e

# -----------------------
# Variables
# -----------------------
STORAGE_ACCOUNT="codadevsa"
CONTAINER_NAME="sample"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
OUTPUT_DIR="/home/jenkinsadmin/sql_export_output"
LOG_FILE="$OUTPUT_DIR/export_to_blob.log"

SQL_SERVER="test-coda.database.windows.net"
DB_NAME="CODA-2024-5-8-12-4-DEV"
DB_USER="sqladmin"
DB_PASS="M*O+p03"

# Ensure output directory exists
mkdir -p "$OUTPUT_DIR"

OUTPUT_FILE="$OUTPUT_DIR/output_${TIMESTAMP}.csv"

# Full path to sqlcmd (avoid PATH issues in cron)
SQLCMD="/opt/mssql-tools/bin/sqlcmd"

# -----------------------
# Run the SQL query and export results
# -----------------------
$SQLCMD -S "$SQL_SERVER" \
       -d "$DB_NAME" \
       -U "$DB_USER" \
       -P "$DB_PASS" \
       -Q "SELECT TransactionType, SRTitleHeaderID, AVTitleHeaderID, SRTH.Title, SRTH.Artist, PerfType, SSN, [Name] AS PerformerName, [Account#], [Perf_VMA], CntrbAmt, [DeductionPCTAmt] AS DeductAmt, CntbCnt, NetAmt, CntrbShrAmt, [DedShrAmt] AS DeductShrAmt, NetShrAmt, OtherRole, AVSRSec, AVUnSec, AVUnAmtNF, AVSRAmtNF, AVUnAmtF, AVSRAmtF, AVUnNFShr, AVSRNFShr, FiscYr, DistrDate, Src, SrcYear, TransactionCode, BusinessID, RunDate, RunTime, UserID, ParticipantHeaderID, ACCT.IsActive, Acct.CreatedDate, Acct.CreatedBy, FileManagerID, RunID, Acct.ModifiedBy, Acct.ModifiedDate, SrcRunDeptID, SrcRunID, DistQueueID, PLHeaderID, PFM.BusinessFileManagerID, PFM.FileManagerDescription, SRTH.BusinessTitleID FROM Account.DRAllocationAcct ACCT INNER JOIN PlayList.FileManager PFM ON ACCT.FileManagerID=PFM.ID AND PFM.IsActive=1 INNER JOIN Title.SRTitleHeader SRTH ON ACCT.SRTitleHeaderID=SRTH.ID AND SRTH.IsActive=1 WHERE ACCT.IsActive=1" \
       -o "$OUTPUT_FILE" -s "," -W

# -----------------------
# Create container if not exists
# -----------------------
az storage container create \
  --name "$CONTAINER_NAME" \
  --account-name "$STORAGE_ACCOUNT" \
  --auth-mode login -o none

# -----------------------
# Upload to Azure Blob
# -----------------------
if az storage blob upload \
    --account-name "$STORAGE_ACCOUNT" \
    --container-name "$CONTAINER_NAME" \
    --name "$(basename "$OUTPUT_FILE")" \
    --file "$OUTPUT_FILE" \
    --auth-mode login \
    --overwrite -o none; then

    echo "[$(date)] ✅ Uploaded $(basename "$OUTPUT_FILE") to container '$CONTAINER_NAME' in '$STORAGE_ACCOUNT'" >> "$LOG_FILE"
    rm -f "$OUTPUT_FILE"
else
    echo "[$(date)] ❌ Upload failed for $OUTPUT_FILE" >> "$LOG_FILE"
fi


------
chmod +x /home/jenkinsadmin/export_to_blob.sh
------
crontab -e
------
* * * * * /home/jenkinsadmin/export_to_blob.sh >> /home/jenkinsadmin/export_to_blob_cron.log 2>&1
------
To Save in Nano:
Press Ctrl + O → (that’s letter O, not zero)
Nano will show:

File Name to Write: /tmp/crontab.xxxxxx

Press 'Enter' to confirm the filename.

Then press Ctrl + X to exit nano.
------
crontab -l
------
You should see:
* * * * * /run/export_to_blob.sh >> /runexport_to_blob_cron.log 2>&1

Test manually:
sudo /run/export_to_blob.sh

Check logs:
tail -f /run/export_to_blob_cron.log
check your custom success log:
tail -f /run/export_to_blob.log


Check if file is transferred to storage container:
az storage blob list --account-name codadevsa --container-name sample --auth-mode login -o table

az storage blob download     --account-name codadevsa     --container-name sample     --name "output_20251106_121954.csv"     --file "./output_20251106_121954.csv"     --auth-mode login

scp -i /c/Aftra/Jenkins/jekins-buildserver.pem jenkinsadmin@10.0.1.11:/home/jenkinsadmin/<filename> .
Ex:
scp -i /c/Aftra/Jenkins/jekins-buildserver.pem jenkinsadmin@10.0.1.11:/home/jenkinsadmin/output_20251106_121954.csv .
